\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{latex-kit/wacv}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{cite}

% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
%\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}

%{\wacvfinalcopy} % *** Uncomment this line for the final submission

\def\wacvPaperID{0000} % Fake paper ID for the quasi-conference
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
\ifwacvfinal\pagestyle{empty}\fi
\setcounter{page}{1}
\begin{document}

%%%%%%%%% TITLE
\title{Pose Estimation in Videos Using Convolutional Neural Networks and
Inter-Frame Recombination}

\author{Sam Toyer\\
The Australian National University\\
{\tt\small u5568237@anu.edu.au}
}

\maketitle
\ifwacvfinal\thispagestyle{empty}\fi

% Random notes about stuff go here.
%
% Figures which I can include:
% - Diagram showing entire pipeline
% - Correct detections
% - Incorrect detections
% - Illustration of recombination candidate set
% - PCK on PIW for elbows/wrists/shoulders, compared with the same papers which
%   Anoop compares with.
%
% Things I can put in the introduction (not all required; just looking through
% other papers to get ideas):
% - What pose estimation is and why it is important.
% - Challenges in pose estimation
% - Explain different classes of approaches to pose estimation (possibly
%   including their disadvantages). Just need to be careful not to tread on the
%   related work section.
% - Abstractly discuss the approach taken in the paper.
% - Summarise experiments performed and the results of those experiments.
%
% Things I can put in the related work section:
% - Talk about existing approaches and how they compare with one another in
%   terms of results and in terms of the computer vision tools used.
% - Explain why my approach is better (technically rather than empirically)
%
% Contents of the intra-frame part:
% - Talk about Yang & Ramanan's articulated model.
% - Discuss the type-based approach to part detection, and its advantages and
%   disadvantages.
% - Mention how the CNN works (esp. the fact that it's a fully convolutional
%   network, and also the way we produce a feature pyramid).
% - Graphical model and inference.
% - Candidate pose generation with NMS at each scale.
% - How do we use distance transforms to make GM inference more efficient? This
%   was something I didn't fully understand, so I might try to write about it in
%   the hope that I come to grok it better.
% - Talk about training.
%
% Contents of the inter-frame part:
% - Just explain how smoothing and recombination works, from optical flow down
%   to producing the final pose.
% - Should also explain whichever extensions I use from Anoop's paper.
% - How do we find our hyperparameters? This is hard, since we don't train
%   hyperparameters; really, we're just fiddling with them until they give us
%   something we want. I could say that I just started with Anoop's parameters,
%   then removed colour tracking and the skin histogram check, which really
%   shows that I have nothing up my sleeves. I could also mention that it's
%   theoretically possible to do a grid search for better parameters (maybe even
%   run such a search and show the results, with the disclaimer that we're
%   training on the test set).
%
% Things to consider putting in the conclusion and future work section (other
% than a summary, obviously):
% - Anoop's suggestion of using a CNN-based regressor to fine-tune joint
%   location estimates. Need to find some prior art on this; did Anoop just make
%   that up when I was talking to him? It seems like a useful insight, so
%   perhaps someone has tried it already.
% - Anoop's other suggestion about using an R-CNN-style approach to CNN forward
%   prop. Not totally convinced about the merits of that (you really only need
%   to identify windows in which there's definitely no human present at all,
%   which isn't what the R-CNN is doing with its semantic segmentation and
%   region joining steps), so I might leave it out.
% - Improve the CNN by using a newer model (e.g. ILSVRC '15 winners) or
%   decreasing the number of output layers from ~10,000 to a few hundred by
%   doing K-means on entire sets of outgoing limbs attached to a single joint.
%   Perhaps there's also a good PCA-based method hiding somewhere in there.
% - Diverse M-best for candidate generation, instead of the crap I'm using at
%   the moment.
% - Using LBP and optical flow to improve pairwise pose estimation.

%%%%%%%%% ABSTRACT
\begin{abstract}
    This paper presents a method for estimation of articulated human poses in
    video frames. Our approach is comprised of a Convolutional Neural Network
    (CNN) and tree-structured graphical model for independent generation of
    candidate pose sets in each frame, followed by a recombination step which
    makes use of optical flow and pairwise deformation features to produce a
    single, consistent series of poses across an entire sequence. Evaluation on
    the Poses in the Wild dataset validates the usefulness of inter-frame pose
    recombination over single-frame pose estimation alone, and suggests that our
    method significantly improves upon the state-of-the-art in localising
    difficult body parts like wrists and elbows.
\end{abstract}

%%%%%%%%% BODY TEXT
\section{Introduction}

The aim of human pose estimation is to take a sequence of static images or video
frames and output a series of two-dimensional ``skeletons'' representing the
locations of the limbs of any humans in those images. Pose estimation is useful
for higher-level computer vision tasks like identifying clothing
items~\cite{liu2012street,liu2012hi,yamaguchi2012parsing}, recognising
actions~\cite{yao2011does}, or even classifying objects which people interact
with~\cite{delaitre2012scene}.

\section{Related work}

\section{Single-frame candidate set generation}

Our method for generating a candidate pose set in each frame mostly follows
that of Chen and Yuille~\cite{chen2014articulated} % TODO

\subsection{Inference}

\subsection{Learning}

\section{Inter-frame recombination}

Given a set of candidate poses in each frame, the approach of Cherian
\etal~\cite{cherian2014mixing} can be used to produce a consistent series of
poses across an entire video sequence. % TODO

\subsection{Use of optical flow}

\subsection{Choosing parameters}

\section{Experiments}

\subsection{Discussion}

\section{Conclusion and future work}

% NOTE: Only include acknowledgments in the final copy (use \ifwacvstyle ... \fi
% to do this easily)!

\ifwacvfinal{%
\noindent\textbf{Acknowledgements}\quad
% XXX: I think that using [number] as a substitute for the paper name and year
% is considered poor style (was that what Steve complained about last semester?)
I would like to thank the authors of~\cite{chen2014articulated} and
\cite{cherian2014mixing} for making their code publicly available.
}\fi

{\small
\bibliographystyle{latex-kit/ieee}
\bibliography{citations}
}
\end{document}
